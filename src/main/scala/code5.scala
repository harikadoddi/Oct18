//import org.apache.spark.sql.SparkSession
//import org.apache.spark.sql.functions.{col, count, current_date, date_sub, initcap, sum, when}
//
//object code4 {
//  def main(args: Array[String]): Unit = {
//    val spark = SparkSession.builder().appName("code1").master("local[*]").getOrCreate()
//    import spark.implicits._
//    val customers = List(
//      ("karthik", 22),
//      ("neha", 28),
//      ("priya", 40),
//      ("mohan", 55),
//      ("ajay", 32),
//      ("vijay", 18),
//      ("veer", 47),
//      ("aatish", 38),
//      ("animesh", 60),
//      ("nishad", 25)
//    ).toDF("name", "age
//
//
//
//
//
//}
